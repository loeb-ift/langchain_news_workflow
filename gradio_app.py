import gradio as gr
import json
import os
from typing import Dict, List, Any, Optional
import logging
from pathlib import Path
import re
from datetime import datetime

from pipeline import InputConfig, interactive_pipeline

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GradioNewsWorkflow:
    def __init__(self):
        """åˆå§‹åŒ–Gradioæ–°èå·¥ä½œæµç¨‹"""
        # åŠ è¼‰ç’°å¢ƒè®Šé‡
        from dotenv import load_dotenv
        load_dotenv()
        
        self.cfg = InputConfig(
            raw_data="",
            news_type="è²¡ç¶“",
            target_style="ç¶“æ¿Ÿæ—¥å ±",
            word_limit=800,
            tone="å®¢è§€ä¸­æ€§"
        )
        self.ollama_base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.model_name = os.getenv("OLLAMA_MODEL_NAME", "gpt-oss:20b")
        self.llm_client = self._setup_ollama_client()
        self.prompts = self.load_prompts()  # æ·»åŠ é€™è¡Œä¾†åŠ è¼‰æç¤ºè©

    def _setup_ollama_client(self):
        """è¨­ç½®Ollamaå®¢æˆ¶ç«¯"""
        try:
            from ollama import Client
            print(f"ğŸ”— é€£æ¥åˆ° Ollama: {self.ollama_base_url}")
            return Client(host=self.ollama_base_url)
        except ImportError:
            print("è­¦å‘Šï¼šç„¡æ³•å°å…¥ollamaï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬å®¢æˆ¶ç«¯")
            return None

    def update_config(self, new_base_url: str, new_model_name: str) -> str:
        """å‹•æ…‹æ›´æ–°Ollamaé…ç½®"""
        try:
            # é©—è­‰URLæ ¼å¼
            if not new_base_url.startswith('http'):
                return "âŒ éŒ¯èª¤ï¼šURLå¿…é ˆä»¥http://æˆ–https://é–‹é ­"
            
            # æ›´æ–°é…ç½®
            self.ollama_base_url = new_base_url.rstrip('/')
            self.model_name = new_model_name
            
            # é‡æ–°åˆå§‹åŒ–Ollamaå®¢æˆ¶ç«¯
            from ollama import Client
            self.llm_client = Client(host=self.ollama_base_url)
            
            # æ¸¬è©¦é€£æ¥
            try:
                self.llm_client.list()
                return f"âœ… é…ç½®æ›´æ–°æˆåŠŸï¼\nLLMæä¾›å•†ï¼š{self.ollama_base_url}\nä½¿ç”¨æ¨¡å‹ï¼š{self.model_name}"
            except Exception as e:
                return f"âš ï¸ é…ç½®å·²æ›´æ–°ï¼Œä½†é€£æ¥æ¸¬è©¦å¤±æ•—ï¼š{str(e)}"
                
        except Exception as e:
            return f"âŒ é…ç½®æ›´æ–°å¤±æ•—ï¼š{str(e)}"

    def get_available_models(self) -> list:
        """ç²å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼Œè¿”å›åˆ—è¡¨æ ¼å¼"""
        try:
            models = self.llm_client.list()
            model_names = [model['name'] for model in models.get('models', [])]
            return model_names if model_names else [self.model_name]
        except Exception as e:
            print(f"ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—ï¼š{str(e)}")
            return [self.model_name]
    
    def refresh_models_from_host(self, host_url: str) -> tuple:
        """å¾æŒ‡å®šHOSTåˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
        try:
            # é©—è­‰URLæ ¼å¼
            if not host_url.startswith('http'):
                return [self.model_name], "âŒ éŒ¯èª¤ï¼šURLå¿…é ˆä»¥http://æˆ–https://é–‹é ­"
            
            # è‡¨æ™‚å‰µå»ºå®¢æˆ¶ç«¯ç²å–æ¨¡å‹åˆ—è¡¨
            from ollama import Client
            temp_client = Client(host=host_url.rstrip('/'))
            
            # ç²å–æ¨¡å‹åˆ—è¡¨
            response = temp_client.list()
            
            # æ ¹æ“šOllama APIå¯¦éš›éŸ¿æ‡‰æ ¼å¼ç²å–æ¨¡å‹åç¨±
            if isinstance(response, dict) and 'models' in response:
                model_names = [model['name'] for model in response['models']]
            elif isinstance(response, list):
                # æŸäº›ç‰ˆæœ¬çš„Ollamaç›´æ¥è¿”å›åˆ—è¡¨
                model_names = [model['name'] for model in response]
            else:
                # è™•ç†å…¶ä»–å¯èƒ½çš„éŸ¿æ‡‰æ ¼å¼
                model_names = [model['name'] for model in response.models]
            
            if model_names:
                return model_names, f"âœ… æˆåŠŸç²å– {len(model_names)} å€‹æ¨¡å‹"
            else:
                return [self.model_name], "âš ï¸ è©²HOSTæ²’æœ‰å¯ç”¨æ¨¡å‹"
                
        except Exception as e:
            return [self.model_name], f"âŒ ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—ï¼š{str(e)}"
        print("âœ… Gradioæ–°èå·¥ä½œæµç¨‹åˆå§‹åŒ–å®Œæˆ")
    
    def load_prompts(self):
        """åŠ è¼‰æ‰€æœ‰æç¤ºè©æ¨¡æ¿"""
        prompts = {}
        prompts_dir = Path("prompts")
        
        # ç¢ºä¿æç¤ºè©ç›®éŒ„å­˜åœ¨
        prompts_dir.mkdir(exist_ok=True)
        
        # å®šç¾©é»˜èªæç¤ºè©
        default_prompts = {
            "alpha": """ä½ æ˜¯æ–°èåˆ†æå°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹æ–°èå…§å®¹ä¸¦æå–é—œéµä¿¡æ¯ï¼š

æ–°èå…§å®¹ï¼š{content}

æ–°èé¡å‹ï¼š{news_type}
å­—æ•¸é™åˆ¶ï¼š{word_limit}
èªæ°£é¢¨æ ¼ï¼š{tone}
ç›®æ¨™åª’é«”ï¼š{target_style}

è«‹æä¾›ï¼š
1. ä¸»è¦äº‹ä»¶æ‘˜è¦ï¼ˆ100å­—å…§ï¼‰
2. é—œéµäººç‰©å’Œçµ„ç¹”
3. æ™‚é–“å’Œåœ°é»
4. æ½›åœ¨å½±éŸ¿
5. èƒŒæ™¯è³‡è¨Š

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒå°ˆæ¥­å’Œå®¢è§€ã€‚""",
            
            "beta": """åŸºæ–¼ä»¥ä¸‹Alphaéšæ®µåˆ†æçµæœï¼Œè«‹é€²è¡Œæ·±åº¦åˆ†æï¼š

Alphaåˆ†æçµæœï¼š{alpha_result}

æ–°èé¡å‹ï¼š{news_type}
å­—æ•¸é™åˆ¶ï¼š{word_limit}
èªæ°£é¢¨æ ¼ï¼š{tone}
ç›®æ¨™åª’é«”ï¼š{target_style}

è«‹æä¾›ï¼š
1. äº‹ä»¶èƒŒå¾Œçš„æ·±å±¤åŸå› 
2. å¯èƒ½çš„ç™¼å±•è¶¨å‹¢
3. å°ç›¸é—œç”¢æ¥­çš„å½±éŸ¿
4. ç¤¾æœƒå’Œç¶“æ¿Ÿå±¤é¢çš„åˆ†æ
5. å°ˆå®¶è§€é»å’Œé æ¸¬

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒæ·±åº¦å’Œæ´å¯ŸåŠ›ã€‚""",
            
            "gamma": """åŸºæ–¼Alphaå’ŒBetaéšæ®µçš„åˆ†æï¼Œè«‹å‰µå»ºä¸€ç¯‡å°ˆæ¥­çš„æ–°èå ±å°ï¼š

Alphaåˆ†æï¼š{alpha_result}
Betaåˆ†æï¼š{beta_result}

è¦æ±‚ï¼š
- æ–°èé¡å‹ï¼š{news_type}
- å­—æ•¸ï¼š{word_limit}å­—å·¦å³
- èªæ°£ï¼š{tone}
- é¢¨æ ¼ï¼š{target_style}

è«‹å‰µå»ºï¼š
1. å¸å¼•äººçš„æ¨™é¡Œï¼ˆ20å­—å…§ï¼‰
2. å¼•äººå…¥å‹çš„å°è¨€
3. çµæ§‹æ¸…æ™°çš„ä¸»é«”å…§å®¹
4. æœ‰åŠ›çš„çµè«–
5. ä¿æŒå°ˆæ¥­æ€§å’Œå¯è®€æ€§

è«‹ç›´æ¥è¼¸å‡ºå®Œæ•´çš„å ±å°æ–‡ç« ã€‚""",
            
            "delta": """è«‹å°ä»¥ä¸‹æ–°èå ±å°é€²è¡Œæœ€çµ‚å¯©æ ¸å’Œå„ªåŒ–ï¼š

å ±å°å…§å®¹ï¼š{gamma_result}

å¯©æ ¸æ¨™æº–ï¼š
- ç›®æ¨™åª’é«”ï¼š{target_style}
- å­—æ•¸è¦æ±‚ï¼š{word_limit}å­—
- èªæ°£é¢¨æ ¼ï¼š{tone}
- æ–°èé¡å‹ï¼š{news_type}

è«‹æª¢æŸ¥ï¼š
1. äº‹å¯¦æº–ç¢ºæ€§
2. èªè¨€æµæš¢åº¦
3. çµæ§‹å®Œæ•´æ€§
4. æ¨™é¡Œå¸å¼•åŠ›
5. æ•´é«”è³ªé‡
6. æ˜¯å¦ç¬¦åˆç™¼å¸ƒæ¨™æº–

è«‹æä¾›ï¼š
- å„ªåŒ–å¾Œçš„æœ€çµ‚ç‰ˆæœ¬
- ç°¡è¦çš„å¯©æ ¸æ„è¦‹
- ç™¼å¸ƒå»ºè­°

ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"""
        }
        
        # å¾æ–‡ä»¶åŠ è¼‰æç¤ºè©ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨å‰‡å‰µå»º
        for stage, default_prompt in default_prompts.items():
            prompt_file = prompts_dir / f"{stage}_prompt.txt"
            
            if prompt_file.exists():
                try:
                    with open(prompt_file, 'r', encoding='utf-8') as f:
                        prompts[stage] = f.read()
                except Exception as e:
                    print(f"è­¦å‘Šï¼šç„¡æ³•è®€å– {prompt_file}ï¼Œä½¿ç”¨é»˜èªæç¤ºè©: {e}")
                    prompts[stage] = default_prompt
            else:
                # å‰µå»ºé»˜èªæç¤ºè©æ–‡ä»¶
                try:
                    with open(prompt_file, 'w', encoding='utf-8') as f:
                        f.write(default_prompt)
                    prompts[stage] = default_prompt
                    print(f"å·²å‰µå»º {prompt_file} é»˜èªæç¤ºè©")
                except Exception as e:
                    print(f"è­¦å‘Šï¼šç„¡æ³•å‰µå»º {prompt_file}ï¼Œä½¿ç”¨å…§å­˜æç¤ºè©: {e}")
                    prompts[stage] = default_prompt
        
        return prompts

    def process_single_article(self, content):
        """è™•ç†å–®ç¯‡æ–‡ç« çš„å®Œæ•´æµç¨‹"""
        try:
            print(f"é–‹å§‹è™•ç†å–®ç¯‡æ–‡ç« ï¼Œå…§å®¹é•·åº¦: {len(content)} å­—ç¬¦")
            
            # åˆå§‹åŒ–å„éšæ®µçµæœ
            alpha_result = ""
            beta_result = ""
            gamma_result = ""
            delta_result = ""
            
            # åŸ·è¡ŒAlphaéšæ®µ - è³‡è¨Šæ¶æ§‹å¸«
            print("é–‹å§‹Alphaéšæ®µ...")
            alpha_prompt = self.prompts.get("alpha", "").format(
                content=content,
                news_type=self.cfg.news_type,
                word_limit=self.cfg.word_limit,
                tone=self.cfg.tone,
                target_style=self.cfg.target_style
            )
            
            alpha_response = self.llm_client.chat(
                model=self.model_name,
                messages=[{"role": "user", "content": alpha_prompt}],
                stream=False
            )
            
            if hasattr(alpha_response, 'message'):
                alpha_result = alpha_response.message.content
            elif isinstance(alpha_response, dict) and 'message' in alpha_response:
                alpha_result = alpha_response['message']['content']
            else:
                alpha_result = str(alpha_response)
            
            print("Alphaéšæ®µå®Œæˆ")
            
            # åŸ·è¡ŒBetaéšæ®µ - é¢¨æ ¼å¡‘é€ å¸«
            print("é–‹å§‹Betaéšæ®µ...")
            beta_prompt = self.prompts.get("beta", "").format(
                alpha_result=alpha_result,
                news_type=self.cfg.news_type,
                word_limit=self.cfg.word_limit,
                tone=self.cfg.tone,
                target_style=self.cfg.target_style
            )
            
            beta_response = self.llm_client.chat(
                model=self.model_name,
                messages=[{"role": "user", "content": beta_prompt}],
                stream=False
            )
            
            if hasattr(beta_response, 'message'):
                beta_result = beta_response.message.content
            elif isinstance(beta_response, dict) and 'message' in beta_response:
                beta_result = beta_response['message']['content']
            else:
                beta_result = str(beta_response)
            
            print("Betaéšæ®µå®Œæˆ")
            
            # åŸ·è¡ŒGammaéšæ®µ - æ¨™é¡Œç­–ç•¥å¸«
            print("é–‹å§‹Gammaéšæ®µ...")
            gamma_prompt = self.prompts.get("gamma", "").format(
                alpha_result=alpha_result,
                beta_result=beta_result,
                news_type=self.cfg.news_type,
                word_limit=self.cfg.word_limit,
                tone=self.cfg.tone,
                target_style=self.cfg.target_style
            )
            
            gamma_response = self.llm_client.chat(
                model=self.model_name,
                messages=[{"role": "user", "content": gamma_prompt}],
                stream=False
            )
            
            if hasattr(gamma_response, 'message'):
                gamma_result = gamma_response.message.content
            elif isinstance(gamma_response, dict) and 'message' in gamma_response:
                gamma_result = gamma_response['message']['content']
            else:
                gamma_result = str(gamma_response)
            
            print("Gammaéšæ®µå®Œæˆ")
            
            # æå–æ¨™é¡Œï¼ˆå¾Gammaçµæœä¸­æå–ç¬¬ä¸€è¡Œä½œç‚ºæ¨™é¡Œï¼‰
            lines = gamma_result.strip().split('\n')
            selected_headline = lines[0] if lines else "ç„¡æ¨™é¡Œ"
            
            # åŸ·è¡ŒDeltaéšæ®µ - å“è³ªå®ˆé–€å“¡
            print("é–‹å§‹Deltaéšæ®µ...")
            delta_prompt = self.prompts.get("delta", "").format(
                gamma_result=gamma_result,
                news_type=self.cfg.news_type,
                word_limit=self.cfg.word_limit,
                tone=self.cfg.tone,
                target_style=self.cfg.target_style
            )
            
            delta_response = self.llm_client.chat(
                model=self.model_name,
                messages=[{"role": "user", "content": delta_prompt}],
                stream=False
            )
            
            if hasattr(delta_response, 'message'):
                delta_result = delta_response.message.content
            elif isinstance(delta_response, dict) and 'message' in delta_response:
                delta_result = delta_response['message']['content']
            else:
                delta_result = str(delta_response)
            
            print("Deltaéšæ®µå®Œæˆ")
            
            # æ§‹å»ºå®Œæ•´çš„çµæœ
            result = {
                "status": "success",
                "selected_headline": selected_headline,
                "final_content": gamma_result,
                "alpha_analysis": alpha_result,
                "beta_analysis": beta_result,
                "delta_review": delta_result,
                "stages_info": {
                    "alpha": {
                        "title": "Alphaï¼ˆè³‡è¨Šæ¶æ§‹å¸«ï¼‰",
                        "purpose": "å°‡åŸå§‹è³‡æ–™è½‰ç‚ºçµæ§‹åŒ–åˆç¨¿ï¼ˆå°è¨€/ä¸»é«”/èƒŒæ™¯ + è³‡è¨Šæ¶æ§‹ï¼‰",
                        "input_data": f"news_type: {self.cfg.news_type}, word_limit: {self.cfg.word_limit}, tone: {self.cfg.tone}",
                        "expected_output": ["draft_content", "key_points", "info_hierarchy", "completeness_score"],
                        "success_criteria": ["å­—æ•¸â‰¥200", "å…·é—œéµé‡é»", "å®Œæ•´æ€§â‰¥6"]
                    },
                    "beta": {
                        "title": "Betaï¼ˆé¢¨æ ¼å¡‘é€ å¸«ï¼‰",
                        "purpose": "åŸºæ–¼Alphaçµæœé€²è¡Œæ·±åº¦åˆ†æå’Œé¢¨æ ¼å„ªåŒ–",
                        "input_data": "Alphaåˆ†æçµæœ",
                        "expected_output": ["deep_analysis", "trend_prediction", "impact_assessment"],
                        "success_criteria": ["åˆ†ææ·±åº¦â‰¥7", "é æ¸¬åˆç†æ€§â‰¥6", "å½±éŸ¿è©•ä¼°å®Œæ•´"]
                    },
                    "gamma": {
                        "title": "Gammaï¼ˆæ¨™é¡Œç­–ç•¥å¸«ï¼‰",
                        "purpose": "å‰µå»ºå°ˆæ¥­æ–°èå ±å°",
                        "input_data": "Alpha+Betaåˆ†æçµæœ",
                        "expected_output": ["headline", "final_article", "quality_score"],
                        "success_criteria": ["æ¨™é¡Œå¸å¼•åŠ›â‰¥8", "å…§å®¹è³ªé‡â‰¥7", "å­—æ•¸é”æ¨™"]
                    },
                    "delta": {
                        "title": "Deltaï¼ˆå“è³ªå®ˆé–€å“¡ï¼‰",
                        "purpose": "æœ€çµ‚å¯©æ ¸å’Œå„ªåŒ–",
                        "input_data": "å®Œæ•´å ±å°",
                        "expected_output": ["final_review", "optimization_suggestions", "publish_recommendation"],
                        "success_criteria": ["æº–ç¢ºæ€§â‰¥9", "èªè¨€æµæš¢åº¦â‰¥8", "ç™¼å¸ƒå°±ç·’åº¦â‰¥7"]
                    }
                }
            }
            
            print(f"è™•ç†å®Œæˆï¼Œæ¨™é¡Œ: {selected_headline}")
            return result
            
        except Exception as e:
            print(f"ERROR:__main__:è™•ç†æ–‡ç« æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "error": str(e),
                "selected_headline": "",
                "final_content": "",
                "alpha_analysis": "",
                "beta_analysis": "",
                "delta_review": ""
            }
    
    def _format_stage_output(self, stage_name: str, stage_info: Dict, result: Dict) -> str:
        """æ ¼å¼åŒ–éšæ®µè¼¸å‡ºä¿¡æ¯"""
        output = f"=== {stage_info['title']} ===\n"
        output += f"ç›®çš„: {stage_info['purpose']}\n"
        output += f"ä½¿ç”¨è³‡æ–™: {json.dumps(stage_info['input_data'], ensure_ascii=False, indent=2)}\n"
        output += f"é æœŸç”¢å‡º: {json.dumps(stage_info['expected_outputs'], ensure_ascii=False)}\n"
        output += f"æˆåŠŸæ¨™æº–: {json.dumps(stage_info['success_criteria'], ensure_ascii=False)}\n\n"
        
        if stage_name == "alpha":
            output += f"{stage_info['processing_message']}\n"
            output += f"{stage_info['result']}\n"
            if "key_points" in stage_info:
                output += f"{stage_name.capitalize()} é‡é»: {stage_info['key_points']}"
        else:
            output += f"{stage_info['processing_message']}\n"
            output += f"{stage_info['result']}"
        
        return output
    
    def create_interface(self):
        """å‰µå»ºGradioç•Œé¢"""
        
        def process_single_with_progress(content, news_type, target_style, tone, word_limit, special_limit):
            if not content.strip():
                return (
                    "è«‹è¼¸å…¥æ–°èå…§å®¹",
                    "",
                    "",
                    "Alpha éšæ®µ AI è™•ç†ä¸­ï¼Œè«‹ç¨å€™...",
                    "Beta éšæ®µ AI è™•ç†ä¸­ï¼Œè«‹ç¨å€™...",
                    "Gamma éšæ®µ AI è™•ç†ä¸­ï¼Œè«‹ç¨å€™...",
                    "Delta éšæ®µ AI è™•ç†ä¸­ï¼Œè«‹ç¨å€™..."
                )
            
            try:
                # æ›´æ–°é…ç½®
                self.cfg.news_type = news_type
                self.cfg.target_style = target_style
                self.cfg.tone = tone
                self.cfg.word_limit = word_limit
                
                print(f"é–‹å§‹è™•ç†æ–‡ç« ï¼Œåƒæ•¸: news_type={news_type}, target_style={target_style}, tone={tone}, word_limit={word_limit}")
                
                result = self.process_single_article(content)
                
                if isinstance(result, dict) and "error" in result:
                    error_msg = f"âŒ è™•ç†å¤±æ•—: {result['error']}"
                    return (
                        error_msg,
                        "",
                        "",
                        f"{error_msg}\n\n=== Alphaï¼ˆè³‡è¨Šæ¶æ§‹å¸«ï¼‰ ===\nç›®çš„: å°‡åŸå§‹è³‡æ–™è½‰ç‚ºçµæ§‹åŒ–åˆç¨¿\nç‹€æ…‹: è™•ç†å¤±æ•—",
                        f"{error_msg}\n\n=== Betaï¼ˆé¢¨æ ¼å¡‘é€ å¸«ï¼‰ ===\nç›®çš„: å„ªåŒ–å…§å®¹é¢¨æ ¼å’Œçµæ§‹\nç‹€æ…‹: è™•ç†å¤±æ•—",
                        f"{error_msg}\n\n=== Gammaï¼ˆæ¨™é¡Œç­–ç•¥å¸«ï¼‰ ===\nç›®çš„: å‰µå»ºå¸å¼•äººçš„æ¨™é¡Œ\nç‹€æ…‹: è™•ç†å¤±æ•—",
                        f"{error_msg}\n\n=== Deltaï¼ˆå“è³ªå®ˆé–€å“¡ï¼‰ ===\nç›®çš„: æœ€çµ‚å¯©æ ¸å’Œå„ªåŒ–\nç‹€æ…‹: è™•ç†å¤±æ•—"
                    )
                
                # ç²å–å„éšæ®µçš„è©³ç´°ä¿¡æ¯
                stages_info = result.get("stages_info", {})
                
                # æ§‹å»ºæ¯å€‹éšæ®µçš„è©³ç´°è¼¸å‡º
                alpha_detail = f"=== Alphaï¼ˆè³‡è¨Šæ¶æ§‹å¸«ï¼‰ ===\n"
                alpha_detail += f"ç›®çš„: å°‡åŸå§‹è³‡æ–™è½‰ç‚ºçµæ§‹åŒ–åˆç¨¿ï¼ˆå°è¨€/ä¸»é«”/èƒŒæ™¯ + è³‡è¨Šæ¶æ§‹ï¼‰\n"
                alpha_detail += f"ä½¿ç”¨è³‡æ–™: {{'news_type': '{news_type}', 'word_limit': {word_limit}, 'tone': '{tone}'}}\n"
                alpha_detail += f"é æœŸç”¢å‡º: ['draft_content', 'key_points', 'info_hierarchy', 'completeness_score']\n"
                alpha_detail += f"æˆåŠŸæ¨™æº–: ['å­—æ•¸â‰¥200', 'å…·é—œéµé‡é»', 'å®Œæ•´æ€§â‰¥6']\n\n"
                alpha_detail += result.get("alpha_analysis", "Alphaåˆ†æå®Œæˆ")
                
                beta_detail = f"=== Betaï¼ˆé¢¨æ ¼å¡‘é€ å¸«ï¼‰ ===\n"
                beta_detail += f"ç›®çš„: åŸºæ–¼Alphaçµæœé€²è¡Œæ·±åº¦åˆ†æå’Œé¢¨æ ¼å„ªåŒ–\n"
                beta_detail += f"ä½¿ç”¨è³‡æ–™: Alphaåˆ†æçµæœ\n"
                beta_detail += f"é æœŸç”¢å‡º: ['deep_analysis', 'trend_prediction', 'impact_assessment']\n"
                beta_detail += f"æˆåŠŸæ¨™æº–: ['åˆ†ææ·±åº¦â‰¥7', 'é æ¸¬åˆç†æ€§â‰¥6', 'å½±éŸ¿è©•ä¼°å®Œæ•´']\n\n"
                beta_detail += result.get("beta_analysis", "Betaåˆ†æå®Œæˆ")
                
                gamma_detail = f"=== Gammaï¼ˆæ¨™é¡Œç­–ç•¥å¸«ï¼‰ ===\n"
                gamma_detail += f"ç›®çš„: å‰µå»ºå°ˆæ¥­æ–°èå ±å°\n"
                gamma_detail += f"ä½¿ç”¨è³‡æ–™: Alpha+Betaåˆ†æçµæœ\n"
                gamma_detail += f"é æœŸç”¢å‡º: ['headline', 'final_article', 'quality_score']\n"
                gamma_detail += f"æˆåŠŸæ¨™æº–: ['æ¨™é¡Œå¸å¼•åŠ›â‰¥8', 'å…§å®¹è³ªé‡â‰¥7', 'å­—æ•¸é”æ¨™']\n\n"
                gamma_detail += result.get("final_content", "Gammaè™•ç†å®Œæˆ")
                
                delta_detail = f"=== Deltaï¼ˆå“è³ªå®ˆé–€å“¡ï¼‰ ===\n"
                delta_detail += f"ç›®çš„: æœ€çµ‚å¯©æ ¸å’Œå„ªåŒ–\n"
                delta_detail += f"ä½¿ç”¨è³‡æ–™: å®Œæ•´å ±å°\n"
                delta_detail += f"é æœŸç”¢å‡º: ['final_review', 'optimization_suggestions', 'publish_recommendation']\n"
                delta_detail += f"æˆåŠŸæ¨™æº–: ['æº–ç¢ºæ€§â‰¥9', 'èªè¨€æµæš¢åº¦â‰¥8', 'ç™¼å¸ƒå°±ç·’åº¦â‰¥7']\n\n"
                delta_detail += result.get("delta_review", "Deltaå¯©æ ¸å®Œæˆ")
                
                return (
                    "âœ… è™•ç†å®Œæˆï¼",
                    result.get("selected_headline", "ç„¡æ¨™é¡Œ"),
                    result.get("final_content", ""),
                    alpha_detail,
                    beta_detail,
                    gamma_detail,
                    delta_detail
                )
                
            except Exception as e:
                error_msg = f"è™•ç†æ–‡ç« æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                print(f"ERROR:__main__:{error_msg}")
                import traceback
                traceback.print_exc()
                
                return (
                    f"âŒ è™•ç†å¤±æ•—: {error_msg}",
                    "",
                    "",
                    f"=== Alphaï¼ˆè³‡è¨Šæ¶æ§‹å¸«ï¼‰ ===\nç›®çš„: å°‡åŸå§‹è³‡æ–™è½‰ç‚ºçµæ§‹åŒ–åˆç¨¿\nç‹€æ…‹: è™•ç†éŒ¯èª¤ - {str(e)}",
                    f"=== Betaï¼ˆé¢¨æ ¼å¡‘é€ å¸«ï¼‰ ===\nç›®çš„: å„ªåŒ–å…§å®¹é¢¨æ ¼å’Œçµæ§‹\nç‹€æ…‹: è™•ç†éŒ¯èª¤ - {str(e)}",
                    f"=== Gammaï¼ˆæ¨™é¡Œç­–ç•¥å¸«ï¼‰ ===\nç›®çš„: å‰µå»ºå¸å¼•äººçš„æ¨™é¡Œ\nç‹€æ…‹: è™•ç†éŒ¯èª¤ - {str(e)}",
                    f"=== Deltaï¼ˆå“è³ªå®ˆé–€å“¡ï¼‰ ===\nç›®çš„: æœ€çµ‚å¯©æ ¸å’Œå„ªåŒ–\nç‹€æ…‹: è™•ç†éŒ¯èª¤ - {str(e)}"
                )
        
        def process_batch_with_progress(file_obj, news_type, target_style, tone, word_limit, special_limit):
            if not file_obj:
                return "è«‹ä¸Šå‚³CSVæ–‡ä»¶"
            
            try:
                import pandas as pd
                df = pd.read_csv(file_obj.name)
                
                if 'content' not in df.columns:
                    return "CSVæ–‡ä»¶å¿…é ˆåŒ…å«'content'åˆ—"
                
                # æ›´æ–°é…ç½®
                self.cfg.news_type = news_type
                self.cfg.target_style = target_style
                self.cfg.tone = tone
                self.cfg.word_limit = word_limit
                
                results = []
                for idx, row in df.iterrows():
                    content = row['content']
                    if pd.notna(content) and content.strip():
                        result = self.process_single_article(content)
                        results.append(result)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                batch_filename = f"batch_results_{timestamp}.json"
                
                output_dir = Path("outputs")
                output_dir.mkdir(exist_ok=True)
                
                with open(output_dir / batch_filename, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                
                return f"âœ… æ‰¹é‡è™•ç†å®Œæˆï¼å…±è™•ç† {len(results)} ç¯‡æ–‡ç« ï¼Œçµæœå·²ä¿å­˜åˆ°: {output_dir / batch_filename}"
                
            except Exception as e:
                return f"âŒ æ‰¹é‡è™•ç†å¤±æ•—: {str(e)}"
        
        def load_prompt_content(stage):
            """åŠ è¼‰æŒ‡å®šéšæ®µçš„æç¤ºè©å…§å®¹"""
            prompts_dir = Path("prompts")
            prompt_file = prompts_dir / f"{stage.lower()}_prompt.txt"
            
            if prompt_file.exists():
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                return f"æœªæ‰¾åˆ° {stage} éšæ®µçš„æç¤ºè©æ–‡ä»¶"
        
        def save_prompt_content(stage, content):
            """ä¿å­˜æŒ‡å®šéšæ®µçš„æç¤ºè©å…§å®¹"""
            try:
                prompts_dir = Path("prompts")
                prompts_dir.mkdir(exist_ok=True)
                
                prompt_file = prompts_dir / f"{stage.lower()}_prompt.txt"
                with open(prompt_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                # é‡æ–°åŠ è¼‰æç¤ºè©
                self.load_prompts()
                return f"âœ… {stage} éšæ®µæç¤ºè©å·²æ›´æ–°ä¸¦ä¿å­˜"
            except Exception as e:
                return f"âŒ ä¿å­˜å¤±æ•—: {str(e)}"
        
        def reset_prompt_to_default(stage):
            """é‡ç½®ç‚ºé»˜èªæç¤ºè©"""
            defaults = {
                "Alpha": """ä½ æ˜¯æ–°èåˆ†æå°ˆå®¶ï¼Œè«‹åˆ†æä»¥ä¸‹æ–°èå…§å®¹ä¸¦æå–é—œéµä¿¡æ¯ï¼š

æ–°èå…§å®¹ï¼š{content}

è«‹æä¾›ï¼š
1. ä¸»è¦äº‹ä»¶æ‘˜è¦
2. é—œéµäººç‰©å’Œçµ„ç¹”
3. æ™‚é–“å’Œåœ°é»
4. æ½›åœ¨å½±éŸ¿

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒå°ˆæ¥­å’Œå®¢è§€ã€‚""",
                
                "Beta": """åŸºæ–¼ä»¥ä¸‹Alphaéšæ®µåˆ†æçµæœï¼Œè«‹é€²è¡Œæ·±åº¦åˆ†æï¼š

Alphaåˆ†æï¼š{alpha_result}

è«‹æä¾›ï¼š
1. äº‹ä»¶èƒŒå¾Œçš„æ·±å±¤åŸå› 
2. å¯èƒ½çš„ç™¼å±•è¶¨å‹¢
3. å°ç›¸é—œç”¢æ¥­çš„å½±éŸ¿
4. ç¤¾æœƒå’Œç¶“æ¿Ÿå±¤é¢çš„åˆ†æ

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒæ·±åº¦å’Œæ´å¯ŸåŠ›ã€‚""",
                
                "Gamma": """åŸºæ–¼Alphaå’ŒBetaéšæ®µçš„åˆ†æï¼Œè«‹å‰µå»ºä¸€ç¯‡å°ˆæ¥­çš„æ–°èå ±å°ï¼š

Alphaåˆ†æï¼š{alpha_result}
Betaåˆ†æï¼š{beta_result}

è¦æ±‚ï¼š
1. æ¨™é¡Œè¦å¸å¼•äººä¸”æº–ç¢º
2. å…§å®¹è¦æœ‰æ·±åº¦å’Œå»£åº¦
3. çµæ§‹æ¸…æ™°ï¼ŒåŒ…å«å¼•è¨€ã€ä¸»é«”ã€çµè«–
4. å­—æ•¸åœ¨{word_limit}å­—å·¦å³
5. ä½¿ç”¨ç¹é«”ä¸­æ–‡
6. ä¿æŒ{tone}çš„èªèª¿
7. ç¬¦åˆ{target_style}çš„é¢¨æ ¼

è«‹ç›´æ¥è¼¸å‡ºå®Œæ•´çš„å ±å°æ–‡ç« ã€‚""",
                
                "Delta": """è«‹å°ä»¥ä¸‹æ–°èå ±å°é€²è¡Œæœ€çµ‚å¯©æ ¸å’Œå„ªåŒ–ï¼š

å ±å°å…§å®¹ï¼š{gamma_result}

å¯©æ ¸æ¨™æº–ï¼š
1. äº‹å¯¦æº–ç¢ºæ€§
2. èªè¨€æµæš¢åº¦
3. çµæ§‹å®Œæ•´æ€§
4. æ¨™é¡Œå¸å¼•åŠ›
5. æ•´é«”è³ªé‡
6. æ˜¯å¦ç¬¦åˆ{target_style}é¢¨æ ¼
7. æ˜¯å¦é”åˆ°{word_limit}å­—è¦æ±‚

è«‹æä¾›ï¼š
- å„ªåŒ–å¾Œçš„æœ€çµ‚ç‰ˆæœ¬
- ç°¡è¦çš„å¯©æ ¸æ„è¦‹
- æ˜¯å¦é©åˆç™¼å¸ƒçš„å»ºè­°

ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"""
            }
            
            return defaults.get(stage, f"æœªæ‰¾åˆ° {stage} çš„é»˜èªæç¤ºè©")
        
        # å‰µå»ºç•Œé¢
        with gr.Blocks(title="æ–°èæ™ºèƒ½åˆ†æç³»çµ±", theme=gr.themes.Soft()) as app:
            gr.Markdown("# ğŸ“° æ–°èæ™ºèƒ½åˆ†æç³»çµ±")
            gr.Markdown("ä½¿ç”¨AIæŠ€è¡“è‡ªå‹•åˆ†æã€å‰µä½œå’Œå„ªåŒ–æ–°èå…§å®¹")
            
            with gr.Tabs():
                # å–®ç¯‡æ–‡ç« è™•ç†
                with gr.TabItem("å–®ç¯‡æ–‡ç« è™•ç†"):
                    with gr.Row():
                        with gr.Column(scale=2):
                            # é…ç½®å€åŸŸ
                            gr.Markdown("### âš™ï¸ è™•ç†é…ç½®")
                            
                            news_type_dropdown = gr.Dropdown(
                                choices=["è²¡ç¶“", "ç§‘æŠ€", "ç”¢æ¥­", "äº‹ä»¶", "æ”¿ç­–"],
                                value=self.cfg.news_type,
                                label="æ–°èé¡å‹"
                            )
                            
                            target_style_dropdown = gr.Dropdown(
                                choices=["ç¶“æ¿Ÿæ—¥å ±", "ä¸­å¤®ç¤¾", "æ•¸ä½æ™‚ä»£", "åˆ¸å•†ç ”å ±"],
                                value=self.cfg.target_style,
                                label="ç›®æ¨™åª’é«”é¢¨æ ¼"
                            )
                            
                            tone_dropdown = gr.Dropdown(
                                choices=["å®¢è§€ä¸­æ€§", "ç©æ¥µæ­£é¢", "è¬¹æ…ä¿å®ˆ"],
                                value=self.cfg.tone,
                                label="èªæ°£é¢¨æ ¼"
                            )
                            
                            word_limit_slider = gr.Slider(
                                minimum=200,
                                maximum=2000,
                                value=self.cfg.word_limit,
                                step=50,
                                label="ç›®æ¨™å­—æ•¸"
                            )
                            
                            special_limit_text = gr.Textbox(
                                label="ç‰¹æ®Šé™åˆ¶ (å¯é¸å¡«)",
                                placeholder="ä¾‹å¦‚ï¼šé¿å…ä½¿ç”¨å°ˆæ¥­è¡“èªã€åŠ å…¥èƒŒæ™¯èªªæ˜ç­‰...",
                                lines=2
                            )
                            
                            input_text = gr.Textbox(
                                label="æ–°èå…§å®¹",
                                placeholder="è«‹è¼¸å…¥éœ€è¦åˆ†æçš„æ–°èå…§å®¹...",
                                lines=10,
                                max_lines=20
                            )
                            process_btn = gr.Button("ğŸš€ é–‹å§‹åˆ†æ", variant="primary")
                        
                        with gr.Column(scale=3):
                            status_text = gr.Textbox(label="è™•ç†ç‹€æ…‹", interactive=False)
                            title_output = gr.Textbox(label="æ–‡ç« æ¨™é¡Œ", interactive=False)
                            content_output = gr.Textbox(label="æœ€çµ‚å ±å°", lines=15, interactive=False)
                    
                    with gr.Row():
                        with gr.Column():
                            alpha_output = gr.Textbox(
                                label="Alpha åˆ†æéšæ®µ - è³‡è¨Šæ¶æ§‹å¸«",
                                lines=12,
                                interactive=False,
                                value="ç­‰å¾…åˆ†æ..."
                            )
                        with gr.Column():
                            beta_output = gr.Textbox(
                                label="Beta åˆ†æéšæ®µ - é¢¨æ ¼å¡‘é€ å¸«",
                                lines=12,
                                interactive=False,
                                value="ç­‰å¾…åˆ†æ..."
                            )
                    
                    with gr.Row():
                        with gr.Column():
                            gamma_output = gr.Textbox(
                                label="Gamma åˆ†æéšæ®µ - æ¨™é¡Œç­–ç•¥å¸«",
                                lines=12,
                                interactive=False,
                                value="ç­‰å¾…åˆ†æ..."
                            )
                        with gr.Column():
                            delta_output = gr.Textbox(
                                label="Delta åˆ†æéšæ®µ - å“è³ªå®ˆé–€å“¡",
                                lines=12,
                                interactive=False,
                                value="ç­‰å¾…åˆ†æ..."
                            )
                
                # æ‰¹é‡è™•ç†
                with gr.TabItem("æ‰¹é‡è™•ç†"):
                    gr.Markdown("### ğŸ“Š æ‰¹é‡è™•ç†æ–°èæ–‡ç« ")
                    gr.Markdown("ä¸Šå‚³åŒ…å«æ–°èå…§å®¹çš„CSVæ–‡ä»¶ï¼ˆéœ€åŒ…å«'content'åˆ—ï¼‰")
                    
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("#### æ‰¹é‡è™•ç†é…ç½®")
                            batch_news_type = gr.Dropdown(
                                choices=["è²¡ç¶“", "ç§‘æŠ€", "ç”¢æ¥­", "äº‹ä»¶", "æ”¿ç­–"],
                                value=self.cfg.news_type,
                                label="æ–°èé¡å‹"
                            )
                            
                            batch_target_style = gr.Dropdown(
                                choices=["ç¶“æ¿Ÿæ—¥å ±", "ä¸­å¤®ç¤¾", "æ•¸ä½æ™‚ä»£", "åˆ¸å•†ç ”å ±"],
                                value=self.cfg.target_style,
                                label="ç›®æ¨™åª’é«”é¢¨æ ¼"
                            )
                            
                            batch_tone = gr.Dropdown(
                                choices=["å®¢è§€ä¸­æ€§", "ç©æ¥µæ­£é¢", "è¬¹æ…ä¿å®ˆ"],
                                value=self.cfg.tone,
                                label="èªæ°£é¢¨æ ¼"
                            )
                            
                            batch_word_limit = gr.Slider(
                                minimum=200,
                                maximum=2000,
                                value=self.cfg.word_limit,
                                step=50,
                                label="ç›®æ¨™å­—æ•¸"
                            )
                            
                            batch_special_limit = gr.Textbox(
                                label="ç‰¹æ®Šé™åˆ¶ (å¯é¸å¡«)",
                                placeholder="ä¾‹å¦‚ï¼šé¿å…ä½¿ç”¨å°ˆæ¥­è¡“èªã€åŠ å…¥èƒŒæ™¯èªªæ˜ç­‰...",
                                lines=2
                            )
                        
                        with gr.Column():
                            batch_file = gr.File(
                                label="ä¸Šå‚³CSVæ–‡ä»¶",
                                file_types=[".csv"],
                                type="filepath"
                            )
                            batch_btn = gr.Button("ğŸ”„ é–‹å§‹æ‰¹é‡è™•ç†", variant="primary")
                            batch_status = gr.Textbox(label="æ‰¹é‡è™•ç†ç‹€æ…‹", interactive=False)
                
                # æç¤ºè©ç®¡ç†å·¥å…·
                with gr.TabItem("ğŸ“ æç¤ºè©ç®¡ç†å·¥å…·"):
                    gr.Markdown("## ğŸ“ æç¤ºè©ç®¡ç†å·¥å…·")
                    gr.Markdown("åœ¨æ­¤é é¢æ‚¨å¯ä»¥æŸ¥çœ‹ã€ç·¨è¼¯ã€å‰µå»ºå’Œç®¡ç†æç¤ºè©é…ç½®ã€‚")
                    
                    with gr.Row():
                        with gr.Column(scale=1):
                            gr.Markdown("### ğŸ“‹ æç¤ºè©éšæ®µç®¡ç†")
                            
                            stage_selector = gr.Dropdown(
                                choices=["Alpha", "Beta", "Gamma", "Delta"],
                                value="Alpha",
                                label="é¸æ“‡æç¤ºè©éšæ®µ"
                            )
                            
                            with gr.Row():
                                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°")
                                reset_btn = gr.Button("â†©ï¸ é‡ç½®ç‚ºé»˜èª")
                            
                            save_btn = gr.Button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", variant="primary")
                        
                        with gr.Column(scale=3):
                            gr.Markdown("### âœï¸ æç¤ºè©å…§å®¹ç·¨è¼¯å™¨")
                            
                            prompt_editor = gr.Textbox(
                                label="æç¤ºè©å…§å®¹",
                                lines=20,
                                max_lines=25,
                                interactive=True
                            )
                            
                            status_msg = gr.Textbox(
                                label="æ“ä½œç‹€æ…‹",
                                interactive=False
                            )
                
                # ç³»çµ±ä¿¡æ¯
                with gr.TabItem("â„¹ï¸ ç³»çµ±ä¿¡æ¯"):
                    gr.Markdown("### â„¹ï¸ ç³»çµ±ä¿¡æ¯")
                    
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("#### ç³»çµ±é…ç½®")
                            llm_provider_text = gr.Textbox(
                                value=self.ollama_base_url,
                                label="LLMæä¾›å•†",
                                interactive=True,
                                placeholder="ä¾‹å¦‚ï¼šhttp://localhost:11434"
                            )
                            port_text = gr.Textbox(
                                value="7860",
                                label="æœå‹™ç«¯å£",
                                interactive=True,
                                placeholder="ä¾‹å¦‚ï¼š7860"
                            )
                            model_dropdown = gr.Dropdown(
                                choices=[self.model_name],
                                value=self.model_name,
                                label="ä½¿ç”¨æ¨¡å‹",
                                interactive=True,
                                allow_custom_value=True
                            )
                            refresh_models_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", size="sm")
                            update_config_btn = gr.Button("ğŸ”„ æ›´æ–°é…ç½®", variant="primary")
                            config_status_text = gr.Textbox(
                                label="é…ç½®ç‹€æ…‹",
                                interactive=False,
                                value="é…ç½®å°±ç·’"
                            )
                        
                        with gr.Column():
                            gr.Markdown("#### ç³»çµ±ç‹€æ…‹")
                            system_status_text = gr.Textbox(
                                value="å°±ç·’",
                                label="ç³»çµ±ç‹€æ…‹",
                                interactive=False
                            )
            
            # è¨­ç½®äº‹ä»¶è™•ç†
            process_btn.click(
                fn=process_single_with_progress,
                inputs=[
                    input_text,
                    news_type_dropdown,
                    target_style_dropdown,
                    tone_dropdown,
                    word_limit_slider,
                    special_limit_text
                ],
                outputs=[
                    status_text,
                    title_output,
                    content_output,
                    alpha_output,
                    beta_output,
                    gamma_output,
                    delta_output
                ]
            )
            
            batch_btn.click(
                fn=process_batch_with_progress,
                inputs=[
                    batch_file,
                    batch_news_type,
                    batch_target_style,
                    batch_tone,
                    batch_word_limit,
                    batch_special_limit
                ],
                outputs=[batch_status]
            )
            
            # æç¤ºè©ç®¡ç†äº‹ä»¶
            def load_selected_prompt(stage):
                content = load_prompt_content(stage)
                return content, f"âœ… å·²åŠ è¼‰ {stage} éšæ®µæç¤ºè©"
            
            def save_current_prompt(stage, content):
                result = save_prompt_content(stage, content)
                new_content = load_prompt_content(stage)
                return new_content, result
            
            def reset_to_default_prompt(stage):
                default_content = reset_prompt_to_default(stage)
                return default_content, f"âœ… {stage} éšæ®µå·²é‡ç½®ç‚ºé»˜èªæç¤ºè©"
            
            # æç¤ºè©äº‹ä»¶ç¶å®š
            stage_selector.change(
                fn=load_selected_prompt,
                inputs=[stage_selector],
                outputs=[prompt_editor, status_msg]
            )
            
            refresh_btn.click(
                fn=load_selected_prompt,
                inputs=[stage_selector],
                outputs=[prompt_editor, status_msg]
            )
            
            save_btn.click(
                fn=save_current_prompt,
                inputs=[stage_selector, prompt_editor],
                outputs=[prompt_editor, status_msg]
            )
            
            reset_btn.click(
                fn=reset_to_default_prompt,
                inputs=[stage_selector],
                outputs=[prompt_editor, status_msg]
            )
            
            # é…ç½®æ›´æ–°äº‹ä»¶
            def update_system_config(new_base_url, new_model_name):
                """æ›´æ–°ç³»çµ±é…ç½®"""
                status = self.update_config(new_base_url, new_model_name)
                # æ›´æ–°æ¨¡å‹ä¸‹æ‹‰é¸å–®
                models, _ = self.refresh_models_from_host(new_base_url)
                return status, gr.Dropdown(choices=models, value=new_model_name)
            
            def refresh_models_list(host_url):
                """åˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
                models, status_msg = self.refresh_models_from_host(host_url)
                current_model = self.model_name if models and self.model_name in models else (models[0] if models else self.model_name)
                return gr.Dropdown(choices=models, value=current_model), status_msg
            
            # é…ç½®æ›´æ–°å’Œæ¨¡å‹åˆ·æ–°äº‹ä»¶
            update_config_btn.click(
                fn=update_system_config,
                inputs=[llm_provider_text, model_dropdown],
                outputs=[config_status_text, model_dropdown]
            )
            
            refresh_models_btn.click(
                fn=refresh_models_list,
                inputs=[llm_provider_text],
                outputs=[model_dropdown, config_status_text]
            )
            
            # å¯¦æ™‚æ›´æ–°é¡¯ç¤ºå€¼
            def refresh_config_display():
                """åˆ·æ–°é…ç½®é¡¯ç¤º"""
                models = self.get_available_models()
                return self.ollama_base_url, gr.Dropdown(choices=models, value=self.model_name)
            
            # é é¢åŠ è¼‰æ™‚åˆ·æ–°é¡¯ç¤º
            app.load(
                fn=refresh_config_display,
                outputs=[llm_provider_text, model_dropdown]
            )
        
        return app

def main():
    """ä¸»å‡½æ•¸"""
    try:
        print("ğŸš€ å•Ÿå‹•æ–°èæ™ºèƒ½åˆ†æç³»çµ±...")
        
        # å‰µå»ºæ‡‰ç”¨å¯¦ä¾‹
        app_instance = GradioNewsWorkflow()
        
        # å‰µå»ºç•Œé¢
        app = app_instance.create_interface()
        
        # å•Ÿå‹•æ‡‰ç”¨
        app.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            debug=True,
            show_error=True
        )
        
    except Exception as e:
        print(f"âŒ å•Ÿå‹•å¤±æ•—: {e}")
        print("è«‹ç¢ºä¿ï¼š")
        print("1. Ollama æœå‹™æ­£åœ¨é‹è¡Œ (http://localhost:11434)")
        print("2. å·²å®‰è£æ‰€éœ€çš„ Python å¥—ä»¶")
        print("3. ç«¯å£ 7860 æœªè¢«ä½”ç”¨")

if __name__ == "__main__":
    main()